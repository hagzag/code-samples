version: '3'

silent: true

tasks:
  cluster-create:
    desc: Starts a local k3d cluster.
    preconditions:
    - sh: "which k3d"
      msg: "k3d missing. Please install it by running 'task tools:install'"
    summary: |
      I was inspired by gitops-local repository which I can across which became my toolkit for a while
      I also borrowed a few concetps that I picked up at various places from external-secrets to ingress, reloader and reflector argocd and many others.
      Longer description of the task:
      - Creates a k3d cluster named '{{.CLUSTER_NAME}}' currenlty configured with 1 server and 2 agents.
      - The cluster is configured to use the image 'rancher/k3s:v1.29.4-k3s1'.
      - The cluster is configured to use the network '{{.CLUSTER_NAME}}-net'.
      - The cluster is configured to expose ports 80 and 443.
      - The cluster is configured to create a registry named 'registry.localhost' on port 5002.
      - The cluster is configured to use the volume '/var/lib/rancher/k3s/storage' on the server node.
      - The cluster is configured to use the hostAliases 'k8s.localhost, app.k8s.localhost, demo.k8s.localhost, app.k8s.localhost, example.k8s.localhost, $CLUSTER_NAME.k8s.localhost'.
      - The cluster is configured to wait for 360 seconds for the cluster to be ready.

      - This setup is going to demonstrate how to create a k3d cluster using a template which simulates a cluter mode in this cade 1 master and 2 agents. 
      - IRL this would proebebly be a more scalable option and some agents would be replaced with other agents or more control plane depdneing on your application needs.
      - were going to explore a 12-15 factor app and how to deploy it to a k3d cluster.
      - setup genreal configuration concepts (secrets, configmaps, rotation, update etc)
      - setup ingress and service mesh concepts
      - review monitoring and logging concepts
      - review security concepts
      - review observability concepts
    cmds:
    - k3d cluster list | grep '{{.CLUSTER_NAME}}' || k3d cluster create --config .config/k3d-$CLUSTER_NAME.yaml
    - echo -e "\nYour cluster has been created. Type 'k3d cluster list' to confirm."
    ignore_error: true
    interactive: true
  
  delete-cluster:
    cmds:
    - k3d cluster list
    - k3d cluster delete $CLUSTER_NAME

  hosts-file:
    desc: Adds a line to the hosts file if it doesn't already exist.
    generates:
      - .config/.etchosts
    summary: |
      - Checks if the specified line is present in the hosts file.
      - If the line doesn't exist, adds it to the hosts file.
    # params:
    #   - name: CLUSTER_NAME
    #     desc: Name of the cluster.
    #     type: string
    #     required: true
    cmds:
      - test -f ./.config/.etchosts || touch ./.config/.etchosts
      - |
        cat <<EOF > ./.config/.etchosts
        127.0.0.1 cluster.localhost
        127.0.0.1 k8s.localhost
        127.0.0.1 demo.k8s.localhost
        127.0.0.1 app.k8s.localhost
        127.0.0.1 whoami.k8s.localhost
        127.0.0.1 example.k8s.localhost
        127.0.0.1 chartmuseum.k8s.localhost
        127.0.0.1 awx.k8s.localhost
        EOF
      - grep -qF "127.0.0.1 {{.CLUSTER_NAME}}.k8s.localhost" ./.config/.etchosts || echo "127.0.0.1 {{.CLUSTER_NAME}}.k8s.localhost" | sudo tee -a ./.config/.etchosts

    ignore_error: true

  cluster-template:
    desc: Create a k3d cluster template
    summary: |
      This task will create a k3d cluster template for '{{.CLUSTER_NAME}}' which will be used to create the k3d cluster.
      see `cluster-create` summary for more details.
    generates:
    - .config/k3d.yaml
    requires:
      vars:
        - K3D_LOCAL_STORAGE_DIR_NAME
        - CLUSTER_NAME
    cmds:
    - task: hosts-file
    - |
      echo "K3D_LOCAL_STORAGE_PATH: $K3D_LOCAL_STORAGE_PATH"
      cat<<EOF>.config/k3d-{{.CLUSTER_NAME}}.yaml
      #
      # Twinker with the template at your own risk :)
      #
      apiVersion: k3d.io/v1alpha5
      kind: Simple
      metadata:
        name: $CLUSTER_NAME
      servers: 1
      agents: 2
      kubeAPI:
        host: "k8s.localhost"
        hostIP: "127.0.0.1"
        hostPort: "6445"
      image: rancher/k3s:v1.29.4-k3s1
      network: $CLUSTER_NAME-net
      ports:
      - port: 80:80
        nodeFilters:
        - loadbalancer
      - port: 443:443
        nodeFilters:
        - loadbalancer
      registries:
        create:
          name: registry.localhost
          host: "0.0.0.0"
          hostPort: "5002"
        config: |
          mirrors:
            "registry.localhost":
              endpoint:
                - http://registry.localhost:5002

      volumes:
      - volume: "{{.ROOT_DIR}}/{{.K3D_LOCAL_STORAGE_DIR_NAME}}:/var/lib/rancher/k3s/storage"
        nodeFilters:
        - server:0
        - agent:*

      hostAliases:
      - ip: 127.0.0.1
        hostnames:
        - k8s.localhost
        - app.k8s.localhost
        - demo.k8s.localhost
        - app.k8s.localhost
        - example.k8s.localhost
        - whoami.k8s.localhost
        - awx.k8s.localhost
        - $CLUSTER_NAME.k8s.localhost
      options:
        k3d:
          wait: true
          timeout: "360s"
          loadbalancer:
            configOverrides:
            - settings.workerConnections=2048
        k3s:
          extraArgs:
          - arg: --disable=traefik
            nodeFilters:
            - server:*
          - arg: --tls-san=localhost,127.0.0.1,registry.localhost,k8s.localhost,cluster.localhost,k8s.localhost,demo.k8s.localhost,app.k8s.localhost,example.k8s.localhost,whoami.k8s.localhost,awx.k8s.localhost,$CLUSTER_NAME.k8s.localhost
            nodeFilters:
            - server:*
          - arg: --kube-proxy-arg=metrics-bind-address=0.0.0.0
            nodeFilters:
            - server:*
            - agent:*
          - arg: --kube-scheduler-arg=bind-address=0.0.0.0
            nodeFilters:
            - server:*
          - arg: --kubelet-arg=node-status-update-frequency=4s
            nodeFilters:
            - server:*
        kubeconfig:
          updateDefaultKubeconfig: true
          switchCurrentContext: true
      EOF

  dns:
    desc: Creates the DNS entry required for the local domain to work.
    preconditions:
      - sh: "which hostctl"
        msg: "hostctl {{.PATH_ERROR}}"
    summary: |
      Configuring Local DNS configuration through hostctl
    cmds:
      - sleep 0.01 && {{if eq OS "windows"}}hostctl add k8s -q < .config/.etchosts{{else}}sudo hostctl add k8s -q < .config/.etchosts{{end}}
      - echo -e "Added 'k8s.localhost' and related domains to your hosts file!"

  certs:
    desc: Creates and uploads local certificates to the cluster as tls secrets
    dir: .config/tls
    generates:
      - .config/tls/ca.pem
      - .config/tls/cert.pem
      - .config/tls/key.pem
    preconditions:
      - sh: "which mkcert"
        msg: "mkcert {{.PATH_ERROR}}"
      - sh: "which kubectl"
        msg: "kubectl {{.PATH_ERROR}}"
    cmds:
      - echo -e "Creating local certificates\n"
      - rm cert.pem key.pem base/tls-secret.yaml ca.pem 2> /dev/null
      - cp -r {{.ROOT_DIR}}/config/tls/* {{.ROOT_DIR}}/.config/tls
      - mkcert -install
      - mkcert -cert-file cert.pem -key-file key.pem -p12-file p12.pem "*.k8s.localhost" k8s.localhost "*.localhost" ::1 127.0.0.1 localhost 127.0.0.1 "*.internal.localhost" "*.local" 2> /dev/null
      - echo -e "Creating certificate secrets on Kubernetes for local TLS enabled by default\n"
      - kubectl config set-context --current --namespace=kube-system --cluster=k3d-{{.CLUSTER_NAME}}
      - kubectl create secret tls tls-secret --cert=cert.pem --key=key.pem --dry-run=client -o yaml >base/tls-secret.yaml
      - kubectl apply -k ./
      - echo -e "\nCertificate resources have been created.\n"
    ignore_error: true

  ns:system:
    cmds:
      - kubectl config set-context --current --namespace=kube-system --cluster=k3d-{{.CLUSTER_NAME}}
    ignore_error: true
